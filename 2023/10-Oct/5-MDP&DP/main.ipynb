{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This computation for the Value Function works if the state space is not too large.\n",
    "- Whe the state space is large, this direct method of solving a linear system of equations will not scale.\n",
    "- We need to resort to numerical methods (DP, RL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarkovRewProcessDict = {\"Current State A\":{\"Action 1\":{\"NextS1fromA\": (\"PNextS1fromA\",\"Reward1\")\n",
    "                                           ,\"NextS2fromA, from A\": (\"PNextS2fromA\",\"Reward2\")},\n",
    "                                           \"Action 2\":{\"NextS1fromA\": (\"PNextS1fromA\",\"Reward1\")\n",
    "                                           ,\"NextS2fromA, from A\": (\"PNextS2fromA\",\"Reward2\")}},\n",
    "                    \n",
    "                     \"Current State B\":{\"NextS1fromB\": (\"PNextS1fromB\",\"Reward3\"),\n",
    "                                        \"NextS2fromB\": (\"PNextS2fromB\",\"Reward4\")}}\n",
    "\n",
    "MarkovRewProcessDict\n",
    "MarkovRewProcessDict[\"Current State A\"]['Action 1'][\"NextS1fromA\"]\n",
    "#MarkovRewProcessDict: Dict[tuple, Dict[tuple, tuple]] = {}\n",
    "\n",
    "MDP_dict: Dict[tuple, Dict[tuple, tuple]] = {}\n",
    "user_capacity = 2\n",
    "user_poisson_lambda = 1.0\n",
    "\n",
    "holding_cost = 1\n",
    "stockout_cost = 10\n",
    "\n",
    "gamma = 0.9 \n",
    "MDP_dict: Dict[tuple, Dict[tuple, tuple]] = {}\n",
    "user_cap = 2\n",
    "poisson_lambda = 1.0\n",
    "\n",
    "holding_cost = 1\n",
    "stockout_cost = 10\n",
    "\n",
    "gamma = 0.9\n",
    "\n",
    "MDP_dict: Dict[tuple, Dict[tuple, tuple]] = {}\n",
    "\n",
    "for alpha in range(user_cap+1):                            \n",
    "                                                               \n",
    "    for beta in range(user_cap + 1 - alpha):\n",
    "        \n",
    "        # This is St, the current state\n",
    "        state = (alpha, beta)                                   \n",
    "\n",
    "        # This is initial inventory, total bike you have at 8AM \n",
    "        init_inv = alpha + beta                         \n",
    "        \n",
    "        # The beta1 is the beta in next state, irrespctive of current state (as the decsion policy is constant)\n",
    "        beta1 = user_cap - init_inv\n",
    "        \n",
    "        base_reward = -alpha* holding_cost\n",
    "        # List of all possible demand you can get\n",
    "        \n",
    "        #dict1 = {}\n",
    "        action = {}\n",
    "\n",
    "        for order in range(user_cap-init_inv +1):\n",
    "            \n",
    "            #action = {}\n",
    "            dict1 = {}\n",
    "            for i in range(init_inv +1):\n",
    "\n",
    "            # if initial demand can meet the deman\n",
    "                if i <= (init_inv-1):\n",
    "                \n",
    "                # probality of specifc demand can happen\n",
    "                    transition_prob = poisson.pmf(i,poisson_lambda)\n",
    "\n",
    "                    dict1[((init_inv - i, order), base_reward)] = transition_prob\n",
    "\n",
    "                         \n",
    "            # if initial demand can not meet the demand\n",
    "                else:\n",
    "                \n",
    "                    transition_prob = 1- poisson.cdf(init_inv -1, poisson_lambda)\n",
    "                \n",
    "                # probability of not meeting the demands\n",
    "                    transition_prob2 = 1- poisson.cdf(init_inv, poisson_lambda)\n",
    "                \n",
    "                # total reward\n",
    "                \n",
    "                    reward = base_reward - stockout_cost*((poisson_lambda*transition_prob) - \\\n",
    "                                                  init_inv*transition_prob2)                \n",
    "\n",
    "                    dict1[((init_inv - i, order),reward)] = transition_prob\n",
    "\n",
    "                    #if state in MDP_dict:\n",
    "\n",
    "            action[order] = dict1\n",
    "\n",
    "        MDP_dict[state]= action\n",
    "MDP_dict\n",
    "MDP_dict\n",
    "from typing import Dict, Tuple\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Constants\n",
    "user_cap = 2\n",
    "poisson_lambda = 1.0\n",
    "holding_cost = 1\n",
    "stockout_cost = 10\n",
    "gamma = 0.9\n",
    "\n",
    "# Initialize the MDP dictionary\n",
    "MDP_dict: Dict[Tuple, Dict[Tuple, float]] = {}\n",
    "\n",
    "# Loop through possible values of alpha and beta\n",
    "for alpha in range(user_cap + 1):\n",
    "    for beta in range(user_cap + 1 - alpha):\n",
    "        state = (alpha, beta)\n",
    "        init_inv = alpha + beta\n",
    "        #beta1 = user_cap - init_inv\n",
    "        base_reward = -alpha * holding_cost\n",
    "\n",
    "        action = {}\n",
    "        for order in range(user_cap - init_inv + 1):\n",
    "            dict1 = {}\n",
    "            for i in range(init_inv + 1):\n",
    "                if i <= (init_inv - 1):\n",
    "                    transition_prob = poisson.pmf(i, poisson_lambda)\n",
    "                    dict1[((init_inv - i, order), base_reward)] = transition_prob\n",
    "                else:\n",
    "                    transition_prob = 1 - poisson.cdf(init_inv - 1, poisson_lambda)\n",
    "                    transition_prob2 = 1 - poisson.cdf(init_inv, poisson_lambda)\n",
    "                    reward = base_reward - stockout_cost * ((poisson_lambda * transition_prob) -\n",
    "                                                            init_inv * transition_prob2)\n",
    "                    dict1[((init_inv - i, order), reward)] = transition_prob\n",
    "            action[order] = dict1\n",
    "        MDP_dict[state] = action\n",
    "\n",
    "MDP_dict"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
